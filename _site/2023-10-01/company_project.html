<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Mordecai</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/site/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/site/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/site/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/site/">
          <h2 class="nav-title">Mordecai</h2>
        </a>
        <ul>
          <li><a href="/site/">About</a></li>
          <li><a href="/site/portfolio/">Portfolio</a></li>
        </ul>
    </div>
  </nav>

    <main>
      <div class="post">
  <h2 class="post-title">Generate a logistics dataset for an order picking task</h2>
  <div class="post-line"></div>

  <h2 id="업로드-예정">업로드 예정</h2>

<h2 id="i-프로젝트-개요">I. 프로젝트 개요</h2>

<p><strong>1. 프로젝트 소개</strong></p>

<ul>
  <li>목표
    <ul>
      <li>box depalletizing 에서 error case object 에 대한 specific 이미지 생성</li>
    </ul>
  </li>
  <li>기대 효과
    <ul>
      <li>Error case 학습을 위해 별도에 학습 데이터 셋 구축을 위한 비용 없이 이미지 생성을 통한 데이터 셋 구축</li>
      <li>Error case 학습을 통해 specific 한 object 에 대해서도 정밀한 detection 가능</li>
    </ul>
  </li>
</ul>

<p><strong>2. 개발 배경 및 필요성</strong></p>

<p><img src="figure1.png" alt="figure1" /></p>

<ul>
  <li>Expected problem
    <ul>
      <li>Data: 현장에는 계속해서 새로운 박스들이 들어오는데, 모든 박스 데이터를 학습 데이터 셋에 포함할 수 없음</li>
      <li>Model: 학습 데이터 안에서 출현 빈도가 적은 박스는 충분하게 학습이 이루어지지 않음</li>
      <li>Service: Error case 에 박스 shape을 잘못 detect 하면, depalletizing 시, 박스가 훼손될 수 있고, 박스가 훼손된 상태에서 고객에게 배송이 될 경우, 책임 문제가 거론될 수 있음</li>
    </ul>
  </li>
  <li>Solution
    <ul>
      <li>Generative Model의 fine tuning을  통해 데이터의 일관성을 유지하면서 박스에 텍스쳐만을 생성하여 새로운 박스 텍스쳐에 강건할 수 있도록 하는 data augmentation 적용</li>
    </ul>
  </li>
</ul>

<p><strong>3. 프로젝트 시나리오</strong></p>

<p><img src="figure2.png" alt="figure2" /></p>

<p><strong>4. 프로젝트 특성</strong></p>

<ul>
  <li>이점
    <ul>
      <li>실험결과를 바탕으로 Error case 에 대한 조치가 가능하고, box depalletizing 모델에 성능을 저해하지 않음</li>
      <li>Data augmentation 효과를 통해 학습 가능한 분포를 넓혀 robust한 추론이 가능하도록 유도할 수 있음</li>
    </ul>
  </li>
  <li>요구사항
    <ul>
      <li>기존에 라벨링 정보와 데이터 셋(최소 100장).</li>
      <li>현장 환경에서 촬영한 box 사진 5-10장</li>
    </ul>
  </li>
</ul>

<p><strong>5. 실험 환경</strong></p>

<ul>
  <li>Cascade Mask R-CNN
    <ul>
      <li>backbone: Swin Transformer(small_tiny)</li>
      <li>Pretrain: ImageNet-1K</li>
      <li>RTX 3090</li>
    </ul>
  </li>
</ul>

<h2 id="ii-프로젝트-내용">II. 프로젝트 내용</h2>

<p><strong>1.이미지 생성에 문제점</strong></p>

<ul>
  <li>추가적인 annotation 작업을 없도록 하기 위해 물류 센터 환경과 다양한 박스의 구조를 유지한채 박스 texture 만을 생성하는 것이 목표</li>
  <li>하지만, 생성 모델은 다양한 입력 데이터를 통해 High quality 에 이미지를 다양하게 생성하는 것이 가능하지만, 일관성 있는 개인화 이미지를 얻기 위해, pretrain model을 downstream task 에 맞게 fine tuning 수행이 필수적임</li>
</ul>

<p><strong>2. 요구사항</strong></p>

<ul>
  <li>
    <p>Fine tuning 을 위해 error case 에 대한 데이터가 필요한데. 확보 가능한 데이터의 수가 제한되고 단순히 fine tuning 만으로는 개인화된 이미지 생성이 어려움</p>
  </li>
  <li>
    <p>따라서, Few shot learning 과 추가적인 condition을 줄 수 있는 방법을 적용하여 개인화된 데이터를 얻을 수 있도록 해야함</p>
  </li>
</ul>

<p><strong>3. Generative Model</strong></p>

<ul>
  <li>Model
    <ul>
      <li>GAN
        <ul>
          <li>학습, 생성 속도 측면에서 diffusion 기반의 모델에 비해 상대적으로 빠른 생성 속도를 가지고 있지만, 학습이 불안정</li>
        </ul>
      </li>
      <li>Diffusion
        <ul>
          <li>안정적인 학습과 고품질에 이미지 생성이 가능하지만, 계산 비용이 큼</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Learning
    <ul>
      <li>Few shot learning
  <img src="figure3.png" alt="Few shot learning" />
        <ul>
          <li>Few-shot Image Generation via Cross-domain Correspondence(Utkarsh Ojha, undefined., et al, “Few-shot Image Generation via Cross-domain Correspondence,” 2021.)
  <img src="figure4.png" alt="Utkarsh Ojha, undefined., et al, &quot;Few-shot Image Generation via Cross-domain Correspondence,&quot; 2021." /></li>
          <li>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation(Nataniel Ruiz, undefined., et al, “DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation,” 2023.)
  <img src="figure5.png" alt="Nataniel Ruiz, undefined., et al, &quot;DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation,&quot; 2023." /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>적용 모델
  <img src="figure7.png" alt="figure7" /></li>
</ul>

<p><strong>4. 프로젝트 구성도</strong></p>

<p><img src="figure6.png" alt="figure6" /></p>

<p><strong>5. 프로젝트 수행 계획</strong></p>

<p><img src="figure8.png" alt="figure8" /></p>

<h2 id="iii-프로젝트-수행-내용">III. 프로젝트 수행 내용</h2>

<p><strong>1. 마스킹</strong></p>

<ul>
  <li>물류 센터 환경과 다양한 박스의 구조를 유지한채 박스 texture 만을 생성하기 위해 마스킹 영역으로 생성 범위를 제한</li>
  <li>Prompt 입력은 특정한 박스 texture에 생성에만 집중하고 mask입력은 영역 정보를 제공</li>
  <li>기존 데이터 셋에서 주어진 Segmentation data 정보를 활용하여 특정 부분만 생성할 수 있도록 guide를 제공</li>
</ul>

<p><strong>1-1. 마스킹 생성</strong></p>

<ul>
  <li>고정 마스킹
    <ul>
      <li>우선적으로 물체 범위에 사각형 마스킹을 씌우면, SAM(Segment Anything Model)을 활용해 탐지된 segment 영역별로 마스크를 생성
  <img src="figure9.png" alt="figure9" /></li>
    </ul>
  </li>
  <li>annotation 정보를 활용한 마스킹
    <ul>
      <li>기존 물체에 annotation 값을 가지고 마스킹을 생성
  <img src="figure10.png" alt="figure10" /></li>
    </ul>
  </li>
</ul>

<p><strong>1-2. 비교</strong></p>

<p>고정 마스킹에 경우 모델에 정확도에 따라 부정확안 마스킹이 생성되거나 고정 마스킹 크기 지정에 대한 기준이 명확하지 않음
따라서, annotation 정보를 활용한 마스킹에 각 물체를 마스킹함</p>

<p><strong>2. texture 생성</strong></p>
<ul>
  <li>기존 이미지의 박스 texture 여러개를 error case object 로 적용
<img src="figure11.png" alt="figure11" /></li>
  <li>기존 이미지의 박스 texture 하나만을 error case object 로 적용
<img src="figure12.png" alt="figure12" /></li>
</ul>

<p><strong>2-1 texture 생성 비교</strong></p>

<p>기존 이미지의 박스 texture 여러개를 error case object 로 적용할 경우 마스킹 영역과 생성된 texture 영역이 맞지 않음
따라서, 기존 이미지의 박스 texture 하나만을 error case object 로 적용</p>

<p><strong>3. 데이터 취득</strong></p>
<ul>
  <li>내부 데이터 셋 혹은 자체적 데이터 취득
    <ul>
      <li>A. 박스 주변부까지 취득
        <ul>
          <li>목적: 주변부의 박스도 같이 생성하여 자연스럽게 생성 가능</li>
          <li>한계: 여러 박스의 texture를 생성하기 때문에 생성되는 박스의 수를 prompt로 컨트롤하는 것이 어려움</li>
        </ul>
      </li>
      <li>B. 박스 texture만 취득
        <ul>
          <li>목적: 배경을 컨트롤 할 필요 없음/</li>
          <li>한계: 박스의 구조를 학습하는 것이 어려움</li>
        </ul>
      </li>
      <li>C. 박스 texture 취득과 임의의 배경
        <ul>
          <li>목적: 현장 주변 환경까지 반영한 생성</li>
          <li>한계: 낮은 품질에 이미지를 생성
  <img src="figure13.png" alt="figure13" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>외부 오픈 데이터 셋 혹은 인터넷 상에 이미지 취득
    <ul>
      <li>A. 인터넷 상에 이미지
        <ul>
          <li>목적: 높은 화질에 이미지로 정보량이 많기 때문에, 객체에 디테일을 학습하는 것이 용이</li>
          <li>한계: 시간적 비용 발생
  <img src="figure14.png" alt="figure14" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>3-1. 데이터 취득 방법 비교</strong></p>

<p>외부 오픈 데이터 셋 혹은 인터넷 상에 이미지 취득하여 학습</p>

<p><strong>4. Caption</strong></p>
<ul>
  <li>방향과 색상을 프롬프트로 제어 가능</li>
  <li>이를 통해 다양한 결과를 하나의 texture 에서 생성가능하고 학습 모델에 일반화를 유도할 수 있음
<img src="figure15.png" alt="figure15" /></li>
</ul>

<p><strong>5. depth</strong></p>
<ul>
  <li>Depth condition이 주어졌을 때와 없을 때에 이미지 생성 차이</li>
  <li>Depth condition을 적용하여 texture를 박스 모형에 맞게 생성
<img src="figure16.png" alt="figure16" /></li>
</ul>

<h2 id="iv-결과">IV. 결과</h2>

<ul>
  <li>정성적 결과
    <ul>
      <li>
        <p>원본 이미지와 생성 이미지
  <img src="figure17.png" alt="figure17" /></p>
      </li>
      <li>
        <p>각각의 원본 이미지와 생성 이미지 비교
  <img src="figure18.png" alt="figure18" /></p>
      </li>
      <li>
        <p>Texture 덮어쓰는 것과 다르게 주변 환경에 빛, 그림자, 반사와 같은 요소들도 반영되어 적용
  <img src="figure19.png" alt="figure19" /></p>
      </li>
      <li>
        <p>각각 다른 데이터 셋으로 학습한 Cascade Mask R-CNN 모델에 bbos/segmentation 탐지 결과
  <img src="figure20.png" alt="figure20" /></p>
      </li>
    </ul>
  </li>
  <li>정량적 결과
    <ul>
      <li>테스트 데이터 셋을 통해 각 데이터셋 별로 학습한 모델에 결과값</li>
      <li>생성 데이터 셋을 추가로 학습한 모델이 원본 이미지에 대해 학습된 모델에 학습 성능 저해하지 하지 않고 성능 향상을 이뤄냄
<img src="figure21.png" alt="figure21" /></li>
    </ul>
  </li>
</ul>


</div>

<div class="pagination">
  
  
    <a href="/site/2023-04-01/contest_exhibit_project" class="right next">Next</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2024-10-29 08:32:26 +0900">2024</time> BEOMSU PARK(범수 박). <a href="https://github.com/kssim/about-portfolio/">A.P</a> theme by kssim.
      </span>
    </footer>
  </body>
</html>
